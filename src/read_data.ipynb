{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyreadstat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60a2b1afd23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cohort/src/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cohort/src/utils/data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyreadstat\u001b[0m \u001b[0;31m# loading .sav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyreadstat'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for Classification\n",
    "\n",
    "Details for each dataset are provided in utils/data_loader.py\n",
    "\n",
    "Packages required to load USA_literacy:\n",
    "sas7bdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[USA_literacy_numeracy.sas7bdat] column count mismatch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India_distress (40286, 26)\n",
      "USA_literacy (4661, 40)\n",
      "USA_kidney (42464, 28)\n",
      "India_HIV (9666, 17)\n",
      "Zambia_perception_mc1 (1082, 16)\n",
      "Angola_maternal (10010, 9)\n",
      "Congo_fever (956, 11)\n",
      "Sjogren_ModelA (92016, 3)\n",
      "Sjogren_ModelB (92016, 4)\n",
      "USA_obesity (13160, 9)\n",
      "SouthAmerica_tuberculosis (478, 14)\n",
      "Infection (288, 15)\n",
      "Qatar_antibodies (1894, 10)\n",
      "Maternal_deaths (9258, 12)\n"
     ]
    }
   ],
   "source": [
    "dir_data = '../data/clss'\n",
    "names_data = ['India_distress', 'USA_literacy',  'USA_kidney', 'India_HIV', 'Zambia_perception_mc1', \n",
    "              'Angola_maternal', 'Congo_fever', 'Sjogren_ModelA', 'Sjogren_ModelB', 'USA_obesity', \n",
    "              'SouthAmerica_tuberculosis', 'Infection', 'Qatar_antibodies', 'Maternal_deaths']\n",
    "for name_data in names_data:\n",
    "    X, y, names_covariates = load_clss_data(name_data, dir_data)\n",
    "    print(name_data, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for Regression\n",
    "\n",
    "Details for each dataset are provided in utils/data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch_drinking_inh (12121, 16)\n",
      "Dutch_drinking_wm (12131, 16)\n",
      "Dutch_drinking_sha (12098, 16)\n",
      "Brazil_health_heart (7728, 6)\n",
      "Brazil_health_stroke (9675, 6)\n",
      "Korea_grip (1022, 11)\n",
      "China_glucose_women2 (4568, 11)\n",
      "China_glucose_men2 (4360, 11)\n",
      "Spain_Hair (529, 5)\n",
      "China_HIV (2410, 27)\n"
     ]
    }
   ],
   "source": [
    "dir_data = '../data/regr'\n",
    "\n",
    "names_data = ['Dutch_drinking_inh', 'Dutch_drinking_wm', 'Dutch_drinking_sha', 'Brazil_health_heart', \n",
    "              'Brazil_health_stroke', 'Korea_grip', 'China_glucose_women2', 'China_glucose_men2', \n",
    "              'Spain_Hair', 'China_HIV']\n",
    "\n",
    "for name_data in names_data:\n",
    "    X, y, names_covariates = load_regr_data(name_data, dir_data)\n",
    "    y = y.astype(np.float)\n",
    "\n",
    "    B = np.column_stack([np.min(X, axis = 0), np.max(X, axis = 0)])\n",
    "    vol = box_intersection(B, B)\n",
    "\n",
    "    print(name_data, X.shape, vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, names_covariates = load_regr_data('Dutch_drinking_wm', dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Imputation__1.0' 'Imputation__2.0' 'Imputation__3.0' 'Imputation__4.0'\n",
      " 'Imputation__5.0' 't1wm' 'sex' 't1age' 't1ses' 't1mat_alcohol'\n",
      " 't1pat_alcohol' 't1ysr_del' 't3year_cannabis' 't4year_cannabis'\n",
      " 't3daily_smoking' 't4month_smoking']\n",
      "[ 0.          0.          0.          0.          0.          2.03194643\n",
      "  1.02428287 -0.33311002  1.26949067 -1.41801865 -1.78799688 -0.53252065\n",
      " -0.61682165 -0.6857144  -0.42757434 -0.84370994]\n",
      "1.4743969524630376\n"
     ]
    }
   ],
   "source": [
    "print(names_covariates)\n",
    "print(X[0,:])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, names_covariates = load_regr_data('Brazil_health_stroke', dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year', 'ESFProportion', 'ACSProportion', 'Population', 'GDP', 'DHI Value']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.24037035,  2.42753081,  2.41139135, 26.18918286, 19.91949403,\n",
       "        7.18713784])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ptp(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "\n",
    "beta = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "res  = np.abs(X @ beta - y)\n",
    "core_ind = np.argsort(res)[:int(n / 10)]\n",
    "\n",
    "core_X = X[core_ind]\n",
    "core_y = y[core_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found stable core (1 iterations)\n"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "for i in range(T):\n",
    "    new_beta = np.linalg.solve(core_X.T @ core_X, core_X.T @ core_y)\n",
    "    if np.linalg.norm(new_beta - beta) < 1e-3:\n",
    "        print(f'Found stable core ({i} iterations)')\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        res      = np.abs(X @ new_beta - y)\n",
    "        new_core_ind = np.argsort(res)[:int(n / 10)]\n",
    "        core_X = X[core_ind]\n",
    "        core_y = y[core_ind]\n",
    "        beta = new_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(x, lb, ub):\n",
    "    p = x.copy()\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        if x[i] < lb[i]:\n",
    "            p[i] = lb[i]\n",
    "        elif x[i] > ub[i]:\n",
    "            p[i] = ub[i]\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def in_box(x, lb, ub):\n",
    "    if (x == proj(x, lb, ub)).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def fit(X, Y):\n",
    "    n = len(Y)\n",
    "    X_copy = X.copy()\n",
    "    # X_copy = np.append(X_copy, np.ones((n, 1)), axis = 1)\n",
    "\n",
    "    XTX = X_copy.T @ X_copy\n",
    "    beta_hat = np.linalg.solve(XTX, X_copy.T @ Y)\n",
    "    min_eig = min(np.linalg.eigvals(XTX)) / len(X_copy)\n",
    "    print(beta_hat)\n",
    "    return beta_hat, min_eig\n",
    "\n",
    "\n",
    "def cutoff(std, min_eig, n_core, n_full, alpha, x):\n",
    "    d = len(x)\n",
    "    return std * (np.linalg.norm(x) * np.sqrt(d * np.log(4 * d / alpha) / n_core) / min_eig + np.sqrt(2 * np.log(4 * n_full / alpha)))\n",
    "\n",
    "\n",
    "def res(x, y, beta):\n",
    "    # return abs(y - np.dot(beta[:-1], x) - beta[-1])\n",
    "    return abs(y - np.dot(x, beta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_infty_norm(x, S):\n",
    "    best = 0\n",
    "    for j in range(len(x)):\n",
    "        if S[j] != set():\n",
    "            best = max(best, max([x[j] * s for s in S[j]]))\n",
    "    return best\n",
    "\n",
    "\n",
    "def largest_box_heuristic(X, B):\n",
    "    # B is a d x 2 array containing the maximum allowed box.\n",
    "    # B must contain the origin and the origin must be contained in the final selected region.\n",
    "    # Any valid point x must have B[i,0] <= x[i] <= B[i,1].\n",
    "    # All of the points in X should be within this box.\n",
    "    n, d = X.shape\n",
    "    X2 = X.copy()\n",
    "    B2 = B.copy()\n",
    "    S = [set([-1,1]) for j in range(d)]\n",
    "    # print(S)\n",
    "\n",
    "    while X2.any():\n",
    "        directed_infty_norms = [directed_infty_norm(x, S) for x in X2]\n",
    "        i = np.argmin(directed_infty_norms) # i = point which supports the new side\n",
    "        j = list(np.abs(X2[i]) == directed_infty_norms[i]).index(True) # j = dimension which is being supported\n",
    "        sign = int(np.sign(X2[i, j]))\n",
    "\n",
    "        S[j].remove(sign)\n",
    "        B2[j, int((sign + 1)/2)] = X2[i, j]\n",
    "        # print(X2[i,j])\n",
    "        # print(B2[j, int((sign + 1)/2)])\n",
    "\n",
    "        X2 = X2[[k for k in range(len(X2)) if sign * X2[k, j] < directed_infty_norms[i]]]\n",
    "\n",
    "    return B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.89423907  0.15342818  1.48291035 -8.463658   -2.58521654 -2.86654597]\n",
      "(967, 6)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "core_beta, min_eig = fit(core_X, core_y)\n",
    "\n",
    "s_hat = np.sqrt(np.sum((core_X @ core_beta - core_y) ** 2) / (len(core_y) - len(X[0]) - 1))\n",
    "alpha = 0.05\n",
    "B = np.column_stack([np.min(X, axis = 0), np.max(X, axis = 0)])\n",
    "\n",
    "excluded = np.zeros(n)\n",
    "for k in range(n):\n",
    "    if res(X[k], y[k], core_beta) > cutoff(s_hat, min_eig, int(n / 10), n, alpha, x):\n",
    "        excluded[k] = 1\n",
    "\n",
    "approx_region = largest_box_heuristic(X[excluded == 1], B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.62018517  1.62018517]\n",
      " [-1.03130083  1.39622999]\n",
      " [-1.17729285  1.2340985 ]\n",
      " [-0.13821648 26.05096638]\n",
      " [-0.87601977 19.04347426]\n",
      " [-3.16185809  4.02527975]]\n",
      "[[-1.62018517  1.62018517]\n",
      " [-1.03130083  1.39622999]\n",
      " [-1.17729285  1.2340985 ]\n",
      " [-0.13821648 22.66954056]\n",
      " [-0.87601977 19.04347426]\n",
      " [-3.16185809  4.02527975]]\n"
     ]
    }
   ],
   "source": [
    "print(B)\n",
    "print(approx_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "6e3471743af6312b4f0004e3f2811341d33b1f1345532266a69a5bb4de2a11c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
